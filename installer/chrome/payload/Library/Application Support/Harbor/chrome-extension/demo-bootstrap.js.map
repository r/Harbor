{
  "version": 3,
  "sources": ["../src/browser-compat.ts", "../src/demo-bootstrap.ts"],
  "sourcesContent": ["/**\n * Browser Compatibility Layer\n *\n * Provides a unified API for browser extension functionality across\n * Firefox, Chrome, and Safari.\n *\n * Firefox uses `browser.*` APIs with native Promise support.\n * Chrome uses `chrome.*` APIs (Promise-based in MV3).\n * Safari uses `browser.*` APIs similar to Firefox.\n */\n\n// Detect environment and provide unified API\ndeclare const browser: typeof chrome | undefined;\n\n/**\n * Unified browser API that works across Firefox, Chrome, and Safari.\n * Prefers `browser` namespace (Firefox/Safari) but falls back to `chrome` (Chrome).\n */\nexport const browserAPI = (typeof browser !== 'undefined' ? browser : chrome) as typeof chrome;\n\n/**\n * Get the URL for an extension resource.\n * Safari doesn't have runtime.getURL in all contexts, so we fall back to relative URLs.\n */\nexport function getExtensionURL(path: string): string {\n  // Try runtime.getURL first (works in Firefox, Chrome, and Safari background)\n  if (browserAPI.runtime?.getURL) {\n    return browserAPI.runtime.getURL(path);\n  }\n  \n  // Fallback for Safari popup/sidebar where runtime.getURL doesn't exist\n  // Use relative URL from the extension's base\n  return path;\n}\n\n/**\n * Check if running in Firefox.\n */\nexport function isFirefox(): boolean {\n  return typeof browser !== 'undefined' && navigator.userAgent.includes('Firefox');\n}\n\n/**\n * Check if running in Chrome.\n */\nexport function isChrome(): boolean {\n  return typeof browser === 'undefined' && typeof chrome !== 'undefined';\n}\n\n/**\n * Check if running in Safari.\n */\nexport function isSafari(): boolean {\n  return typeof browser !== 'undefined' && navigator.userAgent.includes('Safari') && !navigator.userAgent.includes('Chrome');\n}\n\n/**\n * Check if the Firefox ML API (browser.trial.ml) is available.\n * Only available in Firefox 134+ with the trialML permission.\n */\nexport function hasFirefoxML(): boolean {\n  if (typeof browser === 'undefined') return false;\n  const trial = (browser as unknown as { trial?: { ml?: unknown } }).trial;\n  return !!trial && !!trial.ml;\n}\n\n/**\n * Check if the Firefox wllama API is available.\n * Only available in Firefox 142+ with the trialML permission.\n */\nexport function hasFirefoxWllama(): boolean {\n  if (typeof browser === 'undefined') return false;\n  const trial = (browser as unknown as { trial?: { ml?: { wllama?: unknown } } }).trial;\n  return !!trial?.ml?.wllama;\n}\n\n/**\n * Check if the sidebar_action API is available.\n * Only available in Firefox.\n */\nexport function hasSidebar(): boolean {\n  return typeof browser !== 'undefined' && 'sidebarAction' in browser;\n}\n\n/**\n * Check if running in a service worker context.\n * Chrome MV3 uses service workers for the background script.\n */\nexport function isServiceWorker(): boolean {\n  return typeof ServiceWorkerGlobalScope !== 'undefined' &&\n    self instanceof ServiceWorkerGlobalScope;\n}\n\n/**\n * Check if the scripting API is available.\n * Available in MV3 extensions on both Chrome and Firefox.\n */\nexport function hasScriptingAPI(): boolean {\n  return 'scripting' in browserAPI;\n}\n\n/**\n * Execute a script in a tab, compatible with both Chrome and Firefox.\n * Falls back to tabs.executeScript for older Firefox versions.\n */\nexport async function executeScriptInTab<T>(\n  tabId: number,\n  func: (...args: unknown[]) => T,\n  args: unknown[] = []\n): Promise<T | undefined> {\n  // Try chrome.scripting first (Chrome MV3, Firefox MV3 with scripting)\n  if (browserAPI.scripting?.executeScript) {\n    const results = await browserAPI.scripting.executeScript({\n      target: { tabId },\n      func: func as () => T,\n      args,\n    });\n    return results?.[0]?.result as T | undefined;\n  }\n\n  // Fallback: browser.tabs.executeScript (Firefox MV2 style)\n  if (typeof browser !== 'undefined' && browser.tabs?.executeScript) {\n    // For this fallback, we need to serialize the function\n    const code = `(${func.toString()}).apply(null, ${JSON.stringify(args)})`;\n    const results = await browser.tabs.executeScript(tabId, { code });\n    return results?.[0] as T | undefined;\n  }\n\n  throw new Error('No script execution API available');\n}\n\n/**\n * Get the current browser name for logging and debugging.\n */\nexport function getBrowserName(): 'firefox' | 'chrome' | 'safari' | 'unknown' {\n  if (isFirefox()) return 'firefox';\n  if (isSafari()) return 'safari';\n  if (isChrome()) return 'chrome';\n  return 'unknown';\n}\n\n/**\n * Log with browser context for debugging.\n */\nexport function logWithBrowser(prefix: string, ...args: unknown[]): void {\n  console.log(`[${prefix}:${getBrowserName()}]`, ...args);\n}\n\n/**\n * Check if the omnibox API is available.\n * Available in Firefox and Chrome, but may have different features.\n */\nexport function hasOmnibox(): boolean {\n  return 'omnibox' in browserAPI;\n}\n\n/**\n * Check if externally_connectable is available.\n * Only Chrome supports onMessageExternal/onConnectExternal.\n */\nexport function hasExternalMessaging(): boolean {\n  return 'onMessageExternal' in browserAPI.runtime;\n}\n\n/**\n * Check if web navigation API is available.\n */\nexport function hasWebNavigation(): boolean {\n  return 'webNavigation' in browserAPI;\n}\n\n/**\n * Check if this is MV3 (Manifest Version 3).\n */\nexport function isManifestV3(): boolean {\n  return browserAPI.runtime.getManifest().manifest_version === 3;\n}\n\n/**\n * Service worker lifecycle handlers for Chrome MV3.\n * These help maintain state across service worker restarts.\n */\nexport const serviceWorkerLifecycle = {\n  /**\n   * Register a startup handler that runs when the service worker starts.\n   * This is useful for restoring state in Chrome MV3.\n   */\n  onStartup(handler: () => void): void {\n    if (browserAPI.runtime.onStartup) {\n      browserAPI.runtime.onStartup.addListener(handler);\n    }\n  },\n\n  /**\n   * Register an install/update handler.\n   * Runs on first install or extension update.\n   */\n  onInstalled(handler: (details: { reason: string; previousVersion?: string }) => void): void {\n    if (browserAPI.runtime.onInstalled) {\n      browserAPI.runtime.onInstalled.addListener(handler);\n    }\n  },\n\n  /**\n   * Register a suspend handler (Chrome MV3 only).\n   * Called when the service worker is about to be terminated.\n   */\n  onSuspend(handler: () => void): void {\n    if (isServiceWorker() && 'onSuspend' in browserAPI.runtime) {\n      (browserAPI.runtime as { onSuspend: { addListener: (h: () => void) => void } }).onSuspend.addListener(handler);\n    }\n  },\n\n  /**\n   * Keep the service worker alive (Chrome MV3).\n   * Use sparingly - Chrome will still terminate after 5 minutes.\n   */\n  keepAlive(): void {\n    if (isServiceWorker()) {\n      // Accessing chrome.storage periodically can help keep the worker alive\n      // but this should be used sparingly\n      setInterval(() => {\n        browserAPI.storage.local.get(null);\n      }, 20000); // Every 20 seconds\n    }\n  }\n};\n\n/**\n * Browser feature summary for debugging.\n */\nexport function getFeatureSummary(): Record<string, boolean | string> {\n  return {\n    browser: getBrowserName(),\n    isServiceWorker: isServiceWorker(),\n    isManifestV3: isManifestV3(),\n    hasSidebar: hasSidebar(),\n    hasOmnibox: hasOmnibox(),\n    hasFirefoxML: hasFirefoxML(),\n    hasFirefoxWllama: hasFirefoxWllama(),\n    hasScriptingAPI: hasScriptingAPI(),\n    hasExternalMessaging: hasExternalMessaging(),\n    hasWebNavigation: hasWebNavigation(),\n  };\n}\n", "/**\n * Demo Bootstrap Script\n * \n * Provides window.ai and window.agent APIs for the chat demo.\n * Communicates with the bridge via the extension's native messaging.\n */\n\n// Make this a module to avoid global scope conflicts\nexport {};\n\nimport { browserAPI } from './browser-compat';\n\n// Types\ninterface TextSession {\n  sessionId: string;\n  prompt(input: string, tools?: ToolDescriptor[]): Promise<string>;\n  promptStreaming(input: string): AsyncIterable<{ type: string; token?: string }>;\n  destroy(): Promise<void>;\n}\n\ninterface ToolDescriptor {\n  name: string;\n  description?: string;\n  inputSchema?: unknown;\n  serverId?: string;\n}\n\n// Bridge RPC helper - goes through extension message passing\nasync function bridgeRequest<T>(method: string, params?: unknown): Promise<T> {\n  // Use browserAPI.runtime.sendMessage to go through the background script\n  const response = await browserAPI.runtime.sendMessage({\n    type: 'bridge_rpc',\n    method,\n    params,\n  }) as { ok: boolean; result?: T; error?: string };\n  \n  if (!response.ok) {\n    throw new Error(response.error || 'Bridge request failed');\n  }\n  return response.result as T;\n}\n\n// Session counter for IDs\nlet sessionCounter = 0;\n\n/**\n * Check if a model supports native tool calling.\n * \n * Native tool calling means the model can receive tools in the API request\n * and return structured tool_calls in the response.\n * \n * Based on chat orchestrator logic\n */\nfunction modelSupportsNativeTools(modelId?: string): boolean {\n  if (!modelId) return false;\n  \n  const modelLower = modelId.toLowerCase();\n  \n  // Parse model ID - format is usually \"provider:model:tag\" or just \"model\"\n  // e.g., \"ollama:llama3.2:latest\" or \"openai:gpt-4o\"\n  const parts = modelId.split(':');\n  const provider = parts.length >= 2 ? parts[0].toLowerCase() : null;\n  const model = parts.length >= 2 ? parts.slice(1).join(':').toLowerCase() : modelLower;\n  \n  // Cloud providers with native tool support\n  const nativeToolProviders = ['openai', 'anthropic', 'mistral', 'groq'];\n  if (provider && nativeToolProviders.includes(provider)) {\n    return true;\n  }\n  \n  // Ollama - only specific models support native tool calling\n  // Note: mistral:7b-instruct (aka mistral:latest) does NOT support native tools\n  if (provider === 'ollama') {\n    const ollamaModelsWithNativeTools = [\n      'llama3.1', 'llama3.2', 'llama3.3',  // Llama 3.1+ has native tool support\n      'mistral-nemo', 'mistral-large',      // Newer Mistral models (not 7b-instruct)\n      'qwen2.5',                            // Qwen 2.5 has tool support\n      'command-r',                          // Command R models\n    ];\n    return ollamaModelsWithNativeTools.some(m => model.includes(m));\n  }\n  \n  return false;\n}\n\n// Create the ai API\nconst ai = {\n  async createTextSession(options?: { systemPrompt?: string; temperature?: number }): Promise<TextSession> {\n    const sessionId = `demo-${++sessionCounter}`;\n    const history: Array<{ role: string; content: string }> = [];\n    \n    if (options?.systemPrompt) {\n      history.push({ role: 'system', content: options.systemPrompt });\n    }\n    \n    return {\n      sessionId,\n      \n      async prompt(input: string, promptTools?: ToolDescriptor[]): Promise<string> {\n        history.push({ role: 'user', content: input });\n        \n        // Get the default model from config, or first configured model\n        let model: string | undefined;\n        try {\n          // First try configured models\n          const configuredRes = await bridgeRequest<{ models: Array<{ model_id: string; is_default: boolean }> }>('llm.list_configured_models');\n          const defaultModel = configuredRes.models?.find(m => m.is_default);\n          if (defaultModel) {\n            model = defaultModel.model_id;\n          } else if (configuredRes.models?.length > 0) {\n            model = configuredRes.models[0].model_id;\n          }\n          \n          // Fallback to legacy default_model\n          if (!model) {\n            const config = await bridgeRequest<{ default_model?: string }>('llm.get_config');\n            model = config.default_model;\n          }\n          \n          // If still no model, throw a clear error\n          if (!model) {\n            throw Object.assign(\n              new Error('No LLM model configured. Please add an LLM provider (like Ollama) in the Harbor sidebar.'),\n              { code: 'ERR_NO_MODEL' }\n            );\n          }\n        } catch (err) {\n          // Re-throw if it's our specific error\n          if (err && typeof err === 'object' && 'code' in err && err.code === 'ERR_NO_MODEL') {\n            throw err;\n          }\n          // Otherwise fall back to letting the bridge decide (may still fail)\n        }\n        \n        // Build request params\n        const requestParams: {\n          messages: typeof history;\n          model?: string;\n          system_prompt?: string;\n          tools?: Array<{ name: string; description?: string; input_schema: unknown }>;\n        } = {\n          messages: history,\n          model,\n        };\n        \n        // Add system prompt if provided\n        if (options?.systemPrompt) {\n          requestParams.system_prompt = options.systemPrompt;\n        }\n        \n        // For models with native tool calling, pass tools directly to the bridge\n        if (promptTools && promptTools.length > 0 && model && modelSupportsNativeTools(model)) {\n          requestParams.tools = promptTools.map(t => ({\n            name: t.name,\n            description: t.description,\n            input_schema: t.inputSchema || { type: 'object', properties: {} },\n          }));\n          console.log(`[demo-bootstrap] Passing ${requestParams.tools.length} tools to native tool calling model`);\n        }\n        \n        // Bridge returns CompletionResponse in OpenAI-compatible format\n        const result = await bridgeRequest<{ \n          content?: string; \n          message?: { content?: string; tool_calls?: Array<{ id: string; function: { name: string; arguments: string } }> };\n          choices?: Array<{ message?: { content?: string; tool_calls?: Array<{ id: string; function: { name: string; arguments: string } }> }; finish_reason?: string }>;\n        }>('llm.chat', requestParams);\n        \n        // Check for native tool calls\n        const toolCalls = result.choices?.[0]?.message?.tool_calls || result.message?.tool_calls;\n        if (toolCalls && toolCalls.length > 0) {\n          // Return the tool call as JSON so it can be parsed\n          const tc = toolCalls[0];\n          const toolCallJson = {\n            name: tc.function.name,\n            parameters: JSON.parse(tc.function.arguments || '{}'),\n          };\n          console.log('[demo-bootstrap] Native tool call detected:', toolCallJson);\n          const content = JSON.stringify(toolCallJson);\n          history.push({ role: 'assistant', content });\n          return content;\n        }\n        \n        // Handle different response formats:\n        // 1. OpenAI format: choices[0].message.content\n        // 2. Simple format: content\n        // 3. Message format: message.content\n        const content = result.choices?.[0]?.message?.content \n          || result.content \n          || result.message?.content;\n          \n        if (!content) {\n          console.error('[demo-bootstrap] Unexpected LLM response format:', result);\n          throw new Error('LLM returned empty or unexpected response');\n        }\n        \n        history.push({ role: 'assistant', content });\n        return content;\n      },\n      \n      async *promptStreaming(input: string): AsyncIterable<{ type: string; token?: string }> {\n        // For now, fall back to non-streaming\n        const response = await (this as TextSession).prompt(input);\n        \n        // Simulate streaming by yielding word by word\n        const words = response.split(/(\\s+)/);\n        for (const word of words) {\n          if (word) {\n            yield { type: 'token', token: word };\n            await new Promise(r => setTimeout(r, 20));\n          }\n        }\n        yield { type: 'done' };\n      },\n      \n      async destroy(): Promise<void> {\n        // Nothing to clean up\n      },\n    };\n  },\n  \n  providers: {\n    async list(): Promise<Array<{ id: string; name: string; available: boolean; isDefault: boolean }>> {\n      try {\n        const result = await bridgeRequest<{ providers: Array<{ id: string; name: string; configured: boolean; is_default?: boolean }> }>('llm.list_providers');\n        return result.providers.map(p => ({\n          id: p.id,\n          name: p.name,\n          available: p.configured,\n          isDefault: p.is_default || false,\n        }));\n      } catch {\n        return [];\n      }\n    },\n    \n    async getActive(): Promise<{ provider: string | null; model: string | null }> {\n      try {\n        const result = await bridgeRequest<{ default_model?: string; default_provider?: string }>('llm.get_config');\n        const parts = result.default_model?.split(':') || [];\n        return {\n          provider: result.default_provider || parts[0] || null,\n          model: parts[1] || null,\n        };\n      } catch {\n        return { provider: null, model: null };\n      }\n    },\n  },\n};\n\n// Create the agent API\nconst agent = {\n  async requestPermissions(_options: { scopes: string[]; reason?: string }): Promise<{ granted: boolean; scopes: Record<string, string> }> {\n    // In demo context, permissions are always granted\n    return {\n      granted: true,\n      scopes: {\n        'model:prompt': 'granted-always',\n        'model:tools': 'granted-always',\n        'mcp:tools.list': 'granted-always',\n        'mcp:tools.call': 'granted-always',\n      },\n    };\n  },\n  \n  permissions: {\n    async list(): Promise<{ origin: string; scopes: Record<string, string> }> {\n      return {\n        origin: 'extension',\n        scopes: {\n          'model:prompt': 'granted-always',\n          'model:tools': 'granted-always',\n          'mcp:tools.list': 'granted-always',\n          'mcp:tools.call': 'granted-always',\n        },\n      };\n    },\n  },\n  \n  tools: {\n    async list(): Promise<ToolDescriptor[]> {\n      try {\n        // Get servers from the background script via browserAPI.runtime\n        const response = await browserAPI.runtime.sendMessage({ type: 'sidebar_get_servers' }) as {\n          ok: boolean;\n          servers?: Array<{ id: string; name: string; running: boolean; tools?: Array<{ name: string; description?: string; inputSchema?: unknown }> }>;\n        };\n        \n        if (!response.ok || !response.servers) {\n          return [];\n        }\n        \n        const tools: ToolDescriptor[] = [];\n        for (const server of response.servers) {\n          // Only include tools from RUNNING servers\n          if (server.running && server.tools) {\n            for (const tool of server.tools) {\n              tools.push({\n                name: `${server.id}/${tool.name}`,\n                description: tool.description,\n                inputSchema: tool.inputSchema,\n                serverId: server.id,\n              });\n            }\n          }\n        }\n        return tools;\n      } catch (err) {\n        console.error('[Demo] Failed to list tools:', err);\n        return [];\n      }\n    },\n    \n    async call(options: { tool: string; args: Record<string, unknown> }): Promise<unknown> {\n      const [serverId, toolName] = options.tool.split('/');\n      if (!serverId || !toolName) {\n        throw new Error('Invalid tool name format. Expected: serverId/toolName');\n      }\n      \n      const response = await browserAPI.runtime.sendMessage({\n        type: 'sidebar_call_tool',\n        serverId,\n        toolName,\n        args: options.args,\n      }) as { ok: boolean; result?: unknown; error?: string };\n      \n      if (!response.ok) {\n        throw new Error(response.error || 'Tool call failed');\n      }\n      \n      return response.result;\n    },\n  },\n  \n  browser: {\n    activeTab: {\n      async readability(): Promise<{ url: string; title: string; text: string }> {\n        // Get active tab content\n        const tabs = await browserAPI.tabs.query({ active: true, currentWindow: true });\n        const tab = tabs[0];\n        \n        if (!tab?.id || !tab.url) {\n          throw new Error('No active tab found');\n        }\n        \n        if (!tab.url.startsWith('http://') && !tab.url.startsWith('https://')) {\n          throw new Error('Cannot read from this type of page');\n        }\n        \n        const results = await browserAPI.scripting.executeScript({\n          target: { tabId: tab.id },\n          func: () => {\n            const clone = document.cloneNode(true) as Document;\n            ['script', 'style', 'noscript', 'nav', 'footer', 'header'].forEach(sel => {\n              clone.querySelectorAll(sel).forEach(el => el.remove());\n            });\n            const main = clone.querySelector('main, article, .content') || clone.body;\n            let text = main?.textContent || '';\n            text = text.replace(/\\s+/g, ' ').trim().slice(0, 10000);\n            return { url: window.location.href, title: document.title, text };\n          },\n        });\n        \n        if (!results?.[0]?.result) {\n          throw new Error('Failed to extract content');\n        }\n        \n        return results[0].result;\n      },\n    },\n  },\n  \n  run(options: { task: string; tools?: string[]; maxToolCalls?: number; useAllTools?: boolean }): AsyncIterable<{\n    type: 'status' | 'tool_call' | 'tool_result' | 'token' | 'final' | 'error';\n    message?: string;\n    tool?: string;\n    args?: unknown;\n    result?: unknown;\n    token?: string;\n    output?: string;\n    error?: { code: string; message: string };\n  }> {\n    const { task, maxToolCalls = 5 } = options;\n    \n    return {\n      async *[Symbol.asyncIterator]() {\n        yield { type: 'status', message: 'Starting agent...' };\n        \n        try {\n          // Get available tools\n          const tools = await agent.tools.list();\n          yield { type: 'status', message: `Found ${tools.length} tools` };\n          \n          // Get the active model to determine if it supports native tool calling\n          let activeModel: string | undefined;\n          try {\n            const configuredRes = await bridgeRequest<{ models: Array<{ model_id: string; is_default: boolean }> }>('llm.list_configured_models');\n            const defaultModel = configuredRes.models?.find(m => m.is_default);\n            activeModel = defaultModel?.model_id || configuredRes.models?.[0]?.model_id;\n          } catch {\n            // Fall back to legacy\n            try {\n              const config = await bridgeRequest<{ default_model?: string }>('llm.get_config');\n              activeModel = config.default_model;\n            } catch {\n              // Ignore\n            }\n          }\n          \n          // Build system prompt based on whether model supports native tool calling\n          // Build system prompt based on model capabilities\n          let systemPrompt: string;\n          const useNativeTools = modelSupportsNativeTools(activeModel);\n          console.log(`[Demo] Active model: ${activeModel}, native tools: ${useNativeTools}`);\n          \n          if (tools.length === 0) {\n            systemPrompt = 'You are a helpful assistant.';\n          } else if (useNativeTools) {\n            // For models with native tool support (llama3.1+, mistral-nemo, etc.)\n            systemPrompt = `You are a helpful assistant with access to tools.\n\n## TOOL SELECTION STRATEGY\n1. Before calling any tool, carefully analyze what the user is asking for\n2. Call a tool ONLY when you need information or capabilities you don't have\n3. Choose the most appropriate tool based on the user's actual intent\n4. Most requests need at most ONE tool call\n\n## ARGUMENT EXTRACTION - CRITICAL\nWhen determining tool arguments:\n1. Use EXACTLY what the user provides - never invent or assume values\n2. If the user references \"this\", \"that\", or similar pronouns, look for the actual content in their message or conversation history\n3. If the user's request is ambiguous or missing required information, ASK for clarification instead of guessing\n4. Do NOT use placeholder or example data - only use actual values from the user\n\nExamples of CORRECT behavior:\n- User: \"reverse hello world\" \u2192 Use \"hello world\" as the argument\n- User: \"what time is it?\" \u2192 Call time tool with no made-up arguments\n- User: \"reverse this\" (with no text provided) \u2192 Ask \"What text would you like me to reverse?\"\n\nExamples of INCORRECT behavior:\n- User: \"reverse this string\" \u2192 Using \"this is a test string\" (WRONG - made up data)\n- User: \"translate this\" \u2192 Using example text (WRONG - should ask what to translate)\n\n## RESPONSE RULES\n1. After receiving a tool result, RESPOND directly to the user\n2. Do NOT call additional tools unless the user's request explicitly requires it\n3. Synthesize tool results into a clear, helpful answer\n\nAfter getting a result, answer the user directly. Do NOT call more tools in a loop.`;\n          } else {\n            // For models WITHOUT native tool support (mistral 7b, llamafile, etc.)\n            // Need explicit instructions on HOW to format tool calls as JSON\n            const toolList = tools.map(t => {\n              const schema = t.inputSchema as Record<string, unknown> | undefined;\n              const properties = schema?.properties as Record<string, { description?: string }> | undefined;\n              const required = schema?.required as string[] | undefined;\n              \n              let paramInfo = '';\n              if (properties) {\n                const params = Object.entries(properties).map(([name, prop]) => {\n                  const isRequired = required?.includes(name);\n                  return `${name}${isRequired ? ' (required)' : ''}: ${prop.description || 'no description'}`;\n                });\n                if (params.length > 0) {\n                  paramInfo = `\\n  Parameters: ${params.join('; ')}`;\n                }\n              }\n              \n              return `- ${t.name}: ${t.description || 'No description'}${paramInfo}`;\n            }).join('\\n');\n            \n            systemPrompt = `You are a helpful assistant with access to tools.\n\n## Available Tools\n${toolList}\n\n## TOOL SELECTION STRATEGY\n1. Before calling any tool, carefully analyze what the user is asking for\n2. Call a tool ONLY when you need information or capabilities you don't have\n3. Choose the most appropriate tool based on the user's actual intent\n4. Most requests need at most ONE tool call\n\n## ARGUMENT EXTRACTION - CRITICAL\nWhen determining tool arguments:\n1. Use EXACTLY what the user provides - never invent or assume values\n2. If the user references \"this\", \"that\", or similar pronouns, look for the actual content in their message or conversation history\n3. If the user's request is ambiguous or missing required information, ASK for clarification instead of guessing\n4. Do NOT use placeholder or example data - only use actual values from the user\n\nCORRECT: User says \"reverse hello world\" \u2192 parameters: {\"text\": \"hello world\"}\nINCORRECT: User says \"reverse this string\" \u2192 parameters: {\"text\": \"this is a test string\"} (WRONG - made up data)\n\nIf the user doesn't provide the actual data needed, respond with a question asking for it.\n\n## How to Call a Tool\nOutput ONLY this JSON (nothing else):\n{\"name\": \"tool_name\", \"parameters\": {}}\n\n## RESPONSE RULES\n1. After receiving tool results, RESPOND to the user in plain text\n2. Do NOT call more tools unless explicitly needed\n3. Do NOT call the same tool twice\n4. Synthesize results into a clear answer\n\n## Example Flow\nUser: \"What time is it?\"\nYou: {\"name\": \"time-wasm/time.now\", \"parameters\": {}}\n[Tool returns: \"2024-01-15T10:30:00Z\"]\nYou: The current time is 10:30 AM UTC on January 15, 2024.\n\nAfter getting a result, answer the user directly. Do NOT output another JSON tool call.`;\n          }\n          \n          // Create session with system prompt\n          const session = await ai.createTextSession({ systemPrompt });\n          \n          // Build tool name to serverId mapping\n          const toolMap: Record<string, string> = {};\n          for (const t of tools) {\n            toolMap[t.name] = t.serverId || '';\n          }\n          \n          let iterations = 0;\n          let currentMessage = task;\n          let finalOutput = '';\n          const calledTools = new Set<string>(); // Track which tools have been called\n          \n          while (iterations < maxToolCalls) {\n            iterations++;\n            yield { type: 'status', message: `Processing (iteration ${iterations})...` };\n            \n            let response: string;\n            try {\n              // Always pass tools - allow chaining different tools\n              response = await session.prompt(currentMessage, useNativeTools ? tools : undefined);\n            } catch (err) {\n              const errorCode = (err && typeof err === 'object' && 'code' in err) ? (err as { code: string }).code : 'ERR_LLM_FAILED';\n              const errorMsg = err instanceof Error ? err.message : 'LLM request failed';\n              yield { type: 'error', error: { code: errorCode, message: errorMsg } };\n              return;\n            }\n            \n            if (!response) {\n              yield { type: 'error', error: { code: 'ERR_EMPTY_RESPONSE', message: 'LLM returned empty response' } };\n              return;\n            }\n            \n            // Try to parse tool call from response\n            const toolCall = parseToolCallFromText(response, Object.keys(toolMap));\n            \n            if (toolCall) {\n              // Check if the tool exists\n              if (toolCall.toolNotFound) {\n                console.log(`[demo-bootstrap] Model tried to call non-existent tool: ${toolCall.requestedTool}`);\n                const availableToolNames = Object.keys(toolMap).map(t => t.split('/').pop()).join(', ');\n                currentMessage = `Error: The tool \"${toolCall.requestedTool}\" does not exist. Available tools are: ${availableToolNames}. Please provide a direct answer to the user.`;\n                continue;\n              }\n              \n              const { name: toolName, parameters: args } = toolCall;\n              const shortToolName = toolName.split('/').pop() || toolName;\n              \n              // Prevent calling the same tool twice (allow different tools)\n              if (calledTools.has(toolName)) {\n                console.log(`[demo-bootstrap] Preventing repeat call to: ${toolName}`);\n                // Force a response by prompting WITHOUT tools\n                try {\n                  const forceMessage = `You already have the result from \"${shortToolName}\". Now answer the user's question: \"${task}\"\n\nRespond in plain text only.`;\n                  const forcedResponse = await session.prompt(forceMessage, undefined); // No tools!\n                  if (forcedResponse && !parseToolCallFromText(forcedResponse, Object.keys(toolMap))) {\n                    finalOutput = forcedResponse;\n                    break;\n                  }\n                } catch {\n                  // Fall through to continue\n                }\n                continue;\n              }\n              calledTools.add(toolName);\n              \n              yield { type: 'tool_call', tool: toolName, args };\n              \n              try {\n                const result = await agent.tools.call({ tool: toolName, args });\n                yield { type: 'tool_result', tool: toolName, result };\n                \n                // Extract text content from MCP result format\n                let resultText: string;\n                if (result && typeof result === 'object' && 'content' in result) {\n                  const content = (result as { content: Array<{ type: string; text?: string }> }).content;\n                  resultText = content\n                    .filter(c => c.type === 'text' && c.text)\n                    .map(c => c.text)\n                    .join('\\n');\n                } else {\n                  resultText = JSON.stringify(result, null, 2);\n                }\n                \n                // Clear instruction to respond, not call more tools\n                currentMessage = `Tool \"${toolName.split('/').pop()}\" returned: ${resultText}\n\nNow respond directly to the user's original question: \"${task}\"\n\nIMPORTANT: Provide your answer in plain text. Do NOT call any more tools.`;\n              } catch (err) {\n                const errorMsg = err instanceof Error ? err.message : 'Unknown error';\n                yield { type: 'tool_result', tool: toolName, error: { code: 'ERR_TOOL_FAILED', message: errorMsg } };\n                currentMessage = `Tool ${toolName} failed: ${errorMsg}. Please provide the best answer you can without using tools.`;\n              }\n            } else {\n              // No tool call detected, this is the final response\n              finalOutput = response;\n              break;\n            }\n          }\n          \n          // If we exhausted iterations without a final response, use the last response\n          if (!finalOutput && iterations >= maxToolCalls) {\n            finalOutput = \"I apologize, but I wasn't able to complete the task within the allowed steps. Based on my attempts, I may need more information or a simpler request.\";\n          }\n          \n          // Stream the final output\n          const words = finalOutput.split(/(\\s+)/);\n          for (const word of words) {\n            if (word) {\n              yield { type: 'token', token: word };\n              await new Promise(r => setTimeout(r, 15));\n            }\n          }\n          \n          yield { type: 'final', output: finalOutput };\n          await session.destroy();\n          \n        } catch (err) {\n          const errorMsg = err instanceof Error ? err.message : 'Unknown error';\n          yield { type: 'error', error: { code: 'ERR_INTERNAL', message: errorMsg } };\n        }\n      },\n    };\n  },\n};\n\n/**\n * Result of parsing a tool call from text.\n */\ninterface ParsedToolCall {\n  name: string;\n  parameters: Record<string, unknown>;\n  /** If true, a tool call was detected but the tool doesn't exist */\n  toolNotFound?: boolean;\n  /** The original tool name that was requested (if not found) */\n  requestedTool?: string;\n}\n\n/**\n * Parse a tool call from LLM text response.\n * Handles JSON format: {\"name\": \"tool_name\", \"parameters\": {...}}\n */\nfunction parseToolCallFromText(\n  text: string, \n  availableTools: string[]\n): ParsedToolCall | null {\n  if (!text) return null;\n  \n  // Clean up the text - remove markdown code blocks if present\n  let cleaned = text.trim();\n  cleaned = cleaned.replace(/^```(?:json)?\\s*/i, '').replace(/\\s*```$/i, '');\n  \n  // Try to find JSON object in the response\n  const jsonMatch = cleaned.match(/\\{[\\s\\S]*\\}/);\n  if (!jsonMatch) return null;\n  \n  try {\n    const parsed = JSON.parse(jsonMatch[0]);\n    \n    // Check for {\"name\": \"...\", \"parameters\": {...}} format\n    if (parsed.name && typeof parsed.name === 'string') {\n      const toolName = parsed.name;\n      const params = parsed.parameters || parsed.arguments || parsed.args || {};\n      \n      // If no tools available, return as not found\n      if (availableTools.length === 0) {\n        return {\n          name: toolName,\n          parameters: params,\n          toolNotFound: true,\n          requestedTool: toolName,\n        };\n      }\n      \n      // Check if this tool exists (try exact match first, then with server prefix)\n      let matchedTool = availableTools.find(t => t === toolName);\n      if (!matchedTool) {\n        // Try matching by suffix (tool name without server prefix)\n        matchedTool = availableTools.find(t => t.endsWith('/' + toolName) || t.endsWith('__' + toolName));\n      }\n      if (!matchedTool) {\n        // Try matching the short name (after the last /)\n        const shortName = toolName.split('/').pop() || toolName;\n        matchedTool = availableTools.find(t => {\n          const tShort = t.split('/').pop() || t;\n          return tShort === shortName;\n        });\n      }\n      if (!matchedTool) {\n        // Try matching by partial name\n        matchedTool = availableTools.find(t => t.includes(toolName) || toolName.includes(t.split('/').pop() || ''));\n      }\n      \n      if (matchedTool) {\n        return {\n          name: matchedTool,\n          parameters: params,\n        };\n      } else {\n        // Tool call detected but tool doesn't exist\n        console.log(`[demo-bootstrap] Tool call detected for non-existent tool: ${toolName}`);\n        console.log(`[demo-bootstrap] Available tools: ${availableTools.join(', ')}`);\n        return {\n          name: toolName,\n          parameters: params,\n          toolNotFound: true,\n          requestedTool: toolName,\n        };\n      }\n    }\n    \n    // Also check for {\"tool\": \"...\", \"args\": {...}} format\n    if (parsed.tool && typeof parsed.tool === 'string') {\n      const toolName = parsed.tool;\n      const params = parsed.args || parsed.arguments || parsed.parameters || {};\n      \n      const matchedTool = availableTools.find(t => \n        t === toolName || t.includes(toolName)\n      );\n      \n      if (matchedTool) {\n        return {\n          name: matchedTool,\n          parameters: params,\n        };\n      } else {\n        return {\n          name: toolName,\n          parameters: params,\n          toolNotFound: true,\n          requestedTool: toolName,\n        };\n      }\n    }\n  } catch {\n    // JSON parse failed, not a tool call\n  }\n  \n  return null;\n}\n\n// Make APIs available globally\n(window as any).ai = ai;\n(window as any).agent = agent;\n\n// Dispatch event to signal APIs are ready\nwindow.dispatchEvent(new CustomEvent('harbor-provider-ready'));\n\nconsole.log('[Harbor Demo] APIs ready:', {\n  'window.ai': typeof (window as any).ai !== 'undefined',\n  'window.agent': typeof (window as any).agent !== 'undefined',\n});\n"],
  "mappings": ";AAkBO,IAAM,aAAc,OAAO,YAAY,cAAc,UAAU;;;ACUtE,eAAe,cAAiB,QAAgB,QAA8B;AAE5E,QAAM,WAAW,MAAM,WAAW,QAAQ,YAAY;AAAA,IACpD,MAAM;AAAA,IACN;AAAA,IACA;AAAA,EACF,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,IAAI,MAAM,SAAS,SAAS,uBAAuB;AAAA,EAC3D;AACA,SAAO,SAAS;AAClB;AAGA,IAAI,iBAAiB;AAUrB,SAAS,yBAAyB,SAA2B;AAC3D,MAAI,CAAC,QAAS,QAAO;AAErB,QAAM,aAAa,QAAQ,YAAY;AAIvC,QAAM,QAAQ,QAAQ,MAAM,GAAG;AAC/B,QAAM,WAAW,MAAM,UAAU,IAAI,MAAM,CAAC,EAAE,YAAY,IAAI;AAC9D,QAAM,QAAQ,MAAM,UAAU,IAAI,MAAM,MAAM,CAAC,EAAE,KAAK,GAAG,EAAE,YAAY,IAAI;AAG3E,QAAM,sBAAsB,CAAC,UAAU,aAAa,WAAW,MAAM;AACrE,MAAI,YAAY,oBAAoB,SAAS,QAAQ,GAAG;AACtD,WAAO;AAAA,EACT;AAIA,MAAI,aAAa,UAAU;AACzB,UAAM,8BAA8B;AAAA,MAClC;AAAA,MAAY;AAAA,MAAY;AAAA;AAAA,MACxB;AAAA,MAAgB;AAAA;AAAA,MAChB;AAAA;AAAA,MACA;AAAA;AAAA,IACF;AACA,WAAO,4BAA4B,KAAK,OAAK,MAAM,SAAS,CAAC,CAAC;AAAA,EAChE;AAEA,SAAO;AACT;AAGA,IAAM,KAAK;AAAA,EACT,MAAM,kBAAkB,SAAiF;AACvG,UAAM,YAAY,QAAQ,EAAE,cAAc;AAC1C,UAAM,UAAoD,CAAC;AAE3D,QAAI,SAAS,cAAc;AACzB,cAAQ,KAAK,EAAE,MAAM,UAAU,SAAS,QAAQ,aAAa,CAAC;AAAA,IAChE;AAEA,WAAO;AAAA,MACL;AAAA,MAEA,MAAM,OAAO,OAAe,aAAiD;AAC3E,gBAAQ,KAAK,EAAE,MAAM,QAAQ,SAAS,MAAM,CAAC;AAG7C,YAAI;AACJ,YAAI;AAEF,gBAAM,gBAAgB,MAAM,cAA4E,4BAA4B;AACpI,gBAAM,eAAe,cAAc,QAAQ,KAAK,OAAK,EAAE,UAAU;AACjE,cAAI,cAAc;AAChB,oBAAQ,aAAa;AAAA,UACvB,WAAW,cAAc,QAAQ,SAAS,GAAG;AAC3C,oBAAQ,cAAc,OAAO,CAAC,EAAE;AAAA,UAClC;AAGA,cAAI,CAAC,OAAO;AACV,kBAAM,SAAS,MAAM,cAA0C,gBAAgB;AAC/E,oBAAQ,OAAO;AAAA,UACjB;AAGA,cAAI,CAAC,OAAO;AACV,kBAAM,OAAO;AAAA,cACX,IAAI,MAAM,0FAA0F;AAAA,cACpG,EAAE,MAAM,eAAe;AAAA,YACzB;AAAA,UACF;AAAA,QACF,SAAS,KAAK;AAEZ,cAAI,OAAO,OAAO,QAAQ,YAAY,UAAU,OAAO,IAAI,SAAS,gBAAgB;AAClF,kBAAM;AAAA,UACR;AAAA,QAEF;AAGA,cAAM,gBAKF;AAAA,UACF,UAAU;AAAA,UACV;AAAA,QACF;AAGA,YAAI,SAAS,cAAc;AACzB,wBAAc,gBAAgB,QAAQ;AAAA,QACxC;AAGA,YAAI,eAAe,YAAY,SAAS,KAAK,SAAS,yBAAyB,KAAK,GAAG;AACrF,wBAAc,QAAQ,YAAY,IAAI,QAAM;AAAA,YAC1C,MAAM,EAAE;AAAA,YACR,aAAa,EAAE;AAAA,YACf,cAAc,EAAE,eAAe,EAAE,MAAM,UAAU,YAAY,CAAC,EAAE;AAAA,UAClE,EAAE;AACF,kBAAQ,IAAI,4BAA4B,cAAc,MAAM,MAAM,qCAAqC;AAAA,QACzG;AAGA,cAAM,SAAS,MAAM,cAIlB,YAAY,aAAa;AAG5B,cAAM,YAAY,OAAO,UAAU,CAAC,GAAG,SAAS,cAAc,OAAO,SAAS;AAC9E,YAAI,aAAa,UAAU,SAAS,GAAG;AAErC,gBAAM,KAAK,UAAU,CAAC;AACtB,gBAAM,eAAe;AAAA,YACnB,MAAM,GAAG,SAAS;AAAA,YAClB,YAAY,KAAK,MAAM,GAAG,SAAS,aAAa,IAAI;AAAA,UACtD;AACA,kBAAQ,IAAI,+CAA+C,YAAY;AACvE,gBAAMA,WAAU,KAAK,UAAU,YAAY;AAC3C,kBAAQ,KAAK,EAAE,MAAM,aAAa,SAAAA,SAAQ,CAAC;AAC3C,iBAAOA;AAAA,QACT;AAMA,cAAM,UAAU,OAAO,UAAU,CAAC,GAAG,SAAS,WACzC,OAAO,WACP,OAAO,SAAS;AAErB,YAAI,CAAC,SAAS;AACZ,kBAAQ,MAAM,oDAAoD,MAAM;AACxE,gBAAM,IAAI,MAAM,2CAA2C;AAAA,QAC7D;AAEA,gBAAQ,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AAC3C,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,gBAAgB,OAAgE;AAErF,cAAM,WAAW,MAAO,KAAqB,OAAO,KAAK;AAGzD,cAAM,QAAQ,SAAS,MAAM,OAAO;AACpC,mBAAW,QAAQ,OAAO;AACxB,cAAI,MAAM;AACR,kBAAM,EAAE,MAAM,SAAS,OAAO,KAAK;AACnC,kBAAM,IAAI,QAAQ,OAAK,WAAW,GAAG,EAAE,CAAC;AAAA,UAC1C;AAAA,QACF;AACA,cAAM,EAAE,MAAM,OAAO;AAAA,MACvB;AAAA,MAEA,MAAM,UAAyB;AAAA,MAE/B;AAAA,IACF;AAAA,EACF;AAAA,EAEA,WAAW;AAAA,IACT,MAAM,OAA6F;AACjG,UAAI;AACF,cAAM,SAAS,MAAM,cAA6G,oBAAoB;AACtJ,eAAO,OAAO,UAAU,IAAI,QAAM;AAAA,UAChC,IAAI,EAAE;AAAA,UACN,MAAM,EAAE;AAAA,UACR,WAAW,EAAE;AAAA,UACb,WAAW,EAAE,cAAc;AAAA,QAC7B,EAAE;AAAA,MACJ,QAAQ;AACN,eAAO,CAAC;AAAA,MACV;AAAA,IACF;AAAA,IAEA,MAAM,YAAwE;AAC5E,UAAI;AACF,cAAM,SAAS,MAAM,cAAqE,gBAAgB;AAC1G,cAAM,QAAQ,OAAO,eAAe,MAAM,GAAG,KAAK,CAAC;AACnD,eAAO;AAAA,UACL,UAAU,OAAO,oBAAoB,MAAM,CAAC,KAAK;AAAA,UACjD,OAAO,MAAM,CAAC,KAAK;AAAA,QACrB;AAAA,MACF,QAAQ;AACN,eAAO,EAAE,UAAU,MAAM,OAAO,KAAK;AAAA,MACvC;AAAA,IACF;AAAA,EACF;AACF;AAGA,IAAM,QAAQ;AAAA,EACZ,MAAM,mBAAmB,UAAgH;AAEvI,WAAO;AAAA,MACL,SAAS;AAAA,MACT,QAAQ;AAAA,QACN,gBAAgB;AAAA,QAChB,eAAe;AAAA,QACf,kBAAkB;AAAA,QAClB,kBAAkB;AAAA,MACpB;AAAA,IACF;AAAA,EACF;AAAA,EAEA,aAAa;AAAA,IACX,MAAM,OAAoE;AACxE,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,QAAQ;AAAA,UACN,gBAAgB;AAAA,UAChB,eAAe;AAAA,UACf,kBAAkB;AAAA,UAClB,kBAAkB;AAAA,QACpB;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,OAAO;AAAA,IACL,MAAM,OAAkC;AACtC,UAAI;AAEF,cAAM,WAAW,MAAM,WAAW,QAAQ,YAAY,EAAE,MAAM,sBAAsB,CAAC;AAKrF,YAAI,CAAC,SAAS,MAAM,CAAC,SAAS,SAAS;AACrC,iBAAO,CAAC;AAAA,QACV;AAEA,cAAM,QAA0B,CAAC;AACjC,mBAAW,UAAU,SAAS,SAAS;AAErC,cAAI,OAAO,WAAW,OAAO,OAAO;AAClC,uBAAW,QAAQ,OAAO,OAAO;AAC/B,oBAAM,KAAK;AAAA,gBACT,MAAM,GAAG,OAAO,EAAE,IAAI,KAAK,IAAI;AAAA,gBAC/B,aAAa,KAAK;AAAA,gBAClB,aAAa,KAAK;AAAA,gBAClB,UAAU,OAAO;AAAA,cACnB,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF;AACA,eAAO;AAAA,MACT,SAAS,KAAK;AACZ,gBAAQ,MAAM,gCAAgC,GAAG;AACjD,eAAO,CAAC;AAAA,MACV;AAAA,IACF;AAAA,IAEA,MAAM,KAAK,SAA4E;AACrF,YAAM,CAAC,UAAU,QAAQ,IAAI,QAAQ,KAAK,MAAM,GAAG;AACnD,UAAI,CAAC,YAAY,CAAC,UAAU;AAC1B,cAAM,IAAI,MAAM,uDAAuD;AAAA,MACzE;AAEA,YAAM,WAAW,MAAM,WAAW,QAAQ,YAAY;AAAA,QACpD,MAAM;AAAA,QACN;AAAA,QACA;AAAA,QACA,MAAM,QAAQ;AAAA,MAChB,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,IAAI,MAAM,SAAS,SAAS,kBAAkB;AAAA,MACtD;AAEA,aAAO,SAAS;AAAA,IAClB;AAAA,EACF;AAAA,EAEA,SAAS;AAAA,IACP,WAAW;AAAA,MACT,MAAM,cAAqE;AAEzE,cAAM,OAAO,MAAM,WAAW,KAAK,MAAM,EAAE,QAAQ,MAAM,eAAe,KAAK,CAAC;AAC9E,cAAM,MAAM,KAAK,CAAC;AAElB,YAAI,CAAC,KAAK,MAAM,CAAC,IAAI,KAAK;AACxB,gBAAM,IAAI,MAAM,qBAAqB;AAAA,QACvC;AAEA,YAAI,CAAC,IAAI,IAAI,WAAW,SAAS,KAAK,CAAC,IAAI,IAAI,WAAW,UAAU,GAAG;AACrE,gBAAM,IAAI,MAAM,oCAAoC;AAAA,QACtD;AAEA,cAAM,UAAU,MAAM,WAAW,UAAU,cAAc;AAAA,UACvD,QAAQ,EAAE,OAAO,IAAI,GAAG;AAAA,UACxB,MAAM,MAAM;AACV,kBAAM,QAAQ,SAAS,UAAU,IAAI;AACrC,aAAC,UAAU,SAAS,YAAY,OAAO,UAAU,QAAQ,EAAE,QAAQ,SAAO;AACxE,oBAAM,iBAAiB,GAAG,EAAE,QAAQ,QAAM,GAAG,OAAO,CAAC;AAAA,YACvD,CAAC;AACD,kBAAM,OAAO,MAAM,cAAc,yBAAyB,KAAK,MAAM;AACrE,gBAAI,OAAO,MAAM,eAAe;AAChC,mBAAO,KAAK,QAAQ,QAAQ,GAAG,EAAE,KAAK,EAAE,MAAM,GAAG,GAAK;AACtD,mBAAO,EAAE,KAAK,OAAO,SAAS,MAAM,OAAO,SAAS,OAAO,KAAK;AAAA,UAClE;AAAA,QACF,CAAC;AAED,YAAI,CAAC,UAAU,CAAC,GAAG,QAAQ;AACzB,gBAAM,IAAI,MAAM,2BAA2B;AAAA,QAC7C;AAEA,eAAO,QAAQ,CAAC,EAAE;AAAA,MACpB;AAAA,IACF;AAAA,EACF;AAAA,EAEA,IAAI,SASD;AACD,UAAM,EAAE,MAAM,eAAe,EAAE,IAAI;AAEnC,WAAO;AAAA,MACL,QAAQ,OAAO,aAAa,IAAI;AAC9B,cAAM,EAAE,MAAM,UAAU,SAAS,oBAAoB;AAErD,YAAI;AAEF,gBAAM,QAAQ,MAAM,MAAM,MAAM,KAAK;AACrC,gBAAM,EAAE,MAAM,UAAU,SAAS,SAAS,MAAM,MAAM,SAAS;AAG/D,cAAI;AACJ,cAAI;AACF,kBAAM,gBAAgB,MAAM,cAA4E,4BAA4B;AACpI,kBAAM,eAAe,cAAc,QAAQ,KAAK,OAAK,EAAE,UAAU;AACjE,0BAAc,cAAc,YAAY,cAAc,SAAS,CAAC,GAAG;AAAA,UACrE,QAAQ;AAEN,gBAAI;AACF,oBAAM,SAAS,MAAM,cAA0C,gBAAgB;AAC/E,4BAAc,OAAO;AAAA,YACvB,QAAQ;AAAA,YAER;AAAA,UACF;AAIA,cAAI;AACJ,gBAAM,iBAAiB,yBAAyB,WAAW;AAC3D,kBAAQ,IAAI,wBAAwB,WAAW,mBAAmB,cAAc,EAAE;AAElF,cAAI,MAAM,WAAW,GAAG;AACtB,2BAAe;AAAA,UACjB,WAAW,gBAAgB;AAEzB,2BAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UA8BjB,OAAO;AAGL,kBAAM,WAAW,MAAM,IAAI,OAAK;AAC9B,oBAAM,SAAS,EAAE;AACjB,oBAAM,aAAa,QAAQ;AAC3B,oBAAM,WAAW,QAAQ;AAEzB,kBAAI,YAAY;AAChB,kBAAI,YAAY;AACd,sBAAM,SAAS,OAAO,QAAQ,UAAU,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,MAAM;AAC9D,wBAAM,aAAa,UAAU,SAAS,IAAI;AAC1C,yBAAO,GAAG,IAAI,GAAG,aAAa,gBAAgB,EAAE,KAAK,KAAK,eAAe,gBAAgB;AAAA,gBAC3F,CAAC;AACD,oBAAI,OAAO,SAAS,GAAG;AACrB,8BAAY;AAAA,gBAAmB,OAAO,KAAK,IAAI,CAAC;AAAA,gBAClD;AAAA,cACF;AAEA,qBAAO,KAAK,EAAE,IAAI,KAAK,EAAE,eAAe,gBAAgB,GAAG,SAAS;AAAA,YACtE,CAAC,EAAE,KAAK,IAAI;AAEZ,2BAAe;AAAA;AAAA;AAAA,EAGzB,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAqCA;AAGA,gBAAM,UAAU,MAAM,GAAG,kBAAkB,EAAE,aAAa,CAAC;AAG3D,gBAAM,UAAkC,CAAC;AACzC,qBAAW,KAAK,OAAO;AACrB,oBAAQ,EAAE,IAAI,IAAI,EAAE,YAAY;AAAA,UAClC;AAEA,cAAI,aAAa;AACjB,cAAI,iBAAiB;AACrB,cAAI,cAAc;AAClB,gBAAM,cAAc,oBAAI,IAAY;AAEpC,iBAAO,aAAa,cAAc;AAChC;AACA,kBAAM,EAAE,MAAM,UAAU,SAAS,yBAAyB,UAAU,OAAO;AAE3E,gBAAI;AACJ,gBAAI;AAEF,yBAAW,MAAM,QAAQ,OAAO,gBAAgB,iBAAiB,QAAQ,MAAS;AAAA,YACpF,SAAS,KAAK;AACZ,oBAAM,YAAa,OAAO,OAAO,QAAQ,YAAY,UAAU,MAAQ,IAAyB,OAAO;AACvG,oBAAM,WAAW,eAAe,QAAQ,IAAI,UAAU;AACtD,oBAAM,EAAE,MAAM,SAAS,OAAO,EAAE,MAAM,WAAW,SAAS,SAAS,EAAE;AACrE;AAAA,YACF;AAEA,gBAAI,CAAC,UAAU;AACb,oBAAM,EAAE,MAAM,SAAS,OAAO,EAAE,MAAM,sBAAsB,SAAS,8BAA8B,EAAE;AACrG;AAAA,YACF;AAGA,kBAAM,WAAW,sBAAsB,UAAU,OAAO,KAAK,OAAO,CAAC;AAErE,gBAAI,UAAU;AAEZ,kBAAI,SAAS,cAAc;AACzB,wBAAQ,IAAI,2DAA2D,SAAS,aAAa,EAAE;AAC/F,sBAAM,qBAAqB,OAAO,KAAK,OAAO,EAAE,IAAI,OAAK,EAAE,MAAM,GAAG,EAAE,IAAI,CAAC,EAAE,KAAK,IAAI;AACtF,iCAAiB,oBAAoB,SAAS,aAAa,0CAA0C,kBAAkB;AACvH;AAAA,cACF;AAEA,oBAAM,EAAE,MAAM,UAAU,YAAY,KAAK,IAAI;AAC7C,oBAAM,gBAAgB,SAAS,MAAM,GAAG,EAAE,IAAI,KAAK;AAGnD,kBAAI,YAAY,IAAI,QAAQ,GAAG;AAC7B,wBAAQ,IAAI,+CAA+C,QAAQ,EAAE;AAErE,oBAAI;AACF,wBAAM,eAAe,qCAAqC,aAAa,uCAAuC,IAAI;AAAA;AAAA;AAGlH,wBAAM,iBAAiB,MAAM,QAAQ,OAAO,cAAc,MAAS;AACnE,sBAAI,kBAAkB,CAAC,sBAAsB,gBAAgB,OAAO,KAAK,OAAO,CAAC,GAAG;AAClF,kCAAc;AACd;AAAA,kBACF;AAAA,gBACF,QAAQ;AAAA,gBAER;AACA;AAAA,cACF;AACA,0BAAY,IAAI,QAAQ;AAExB,oBAAM,EAAE,MAAM,aAAa,MAAM,UAAU,KAAK;AAEhD,kBAAI;AACF,sBAAM,SAAS,MAAM,MAAM,MAAM,KAAK,EAAE,MAAM,UAAU,KAAK,CAAC;AAC9D,sBAAM,EAAE,MAAM,eAAe,MAAM,UAAU,OAAO;AAGpD,oBAAI;AACJ,oBAAI,UAAU,OAAO,WAAW,YAAY,aAAa,QAAQ;AAC/D,wBAAM,UAAW,OAA+D;AAChF,+BAAa,QACV,OAAO,OAAK,EAAE,SAAS,UAAU,EAAE,IAAI,EACvC,IAAI,OAAK,EAAE,IAAI,EACf,KAAK,IAAI;AAAA,gBACd,OAAO;AACL,+BAAa,KAAK,UAAU,QAAQ,MAAM,CAAC;AAAA,gBAC7C;AAGA,iCAAiB,SAAS,SAAS,MAAM,GAAG,EAAE,IAAI,CAAC,eAAe,UAAU;AAAA;AAAA,yDAEnC,IAAI;AAAA;AAAA;AAAA,cAG/C,SAAS,KAAK;AACZ,sBAAM,WAAW,eAAe,QAAQ,IAAI,UAAU;AACtD,sBAAM,EAAE,MAAM,eAAe,MAAM,UAAU,OAAO,EAAE,MAAM,mBAAmB,SAAS,SAAS,EAAE;AACnG,iCAAiB,QAAQ,QAAQ,YAAY,QAAQ;AAAA,cACvD;AAAA,YACF,OAAO;AAEL,4BAAc;AACd;AAAA,YACF;AAAA,UACF;AAGA,cAAI,CAAC,eAAe,cAAc,cAAc;AAC9C,0BAAc;AAAA,UAChB;AAGA,gBAAM,QAAQ,YAAY,MAAM,OAAO;AACvC,qBAAW,QAAQ,OAAO;AACxB,gBAAI,MAAM;AACR,oBAAM,EAAE,MAAM,SAAS,OAAO,KAAK;AACnC,oBAAM,IAAI,QAAQ,OAAK,WAAW,GAAG,EAAE,CAAC;AAAA,YAC1C;AAAA,UACF;AAEA,gBAAM,EAAE,MAAM,SAAS,QAAQ,YAAY;AAC3C,gBAAM,QAAQ,QAAQ;AAAA,QAExB,SAAS,KAAK;AACZ,gBAAM,WAAW,eAAe,QAAQ,IAAI,UAAU;AACtD,gBAAM,EAAE,MAAM,SAAS,OAAO,EAAE,MAAM,gBAAgB,SAAS,SAAS,EAAE;AAAA,QAC5E;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAkBA,SAAS,sBACP,MACA,gBACuB;AACvB,MAAI,CAAC,KAAM,QAAO;AAGlB,MAAI,UAAU,KAAK,KAAK;AACxB,YAAU,QAAQ,QAAQ,qBAAqB,EAAE,EAAE,QAAQ,YAAY,EAAE;AAGzE,QAAM,YAAY,QAAQ,MAAM,aAAa;AAC7C,MAAI,CAAC,UAAW,QAAO;AAEvB,MAAI;AACF,UAAM,SAAS,KAAK,MAAM,UAAU,CAAC,CAAC;AAGtC,QAAI,OAAO,QAAQ,OAAO,OAAO,SAAS,UAAU;AAClD,YAAM,WAAW,OAAO;AACxB,YAAM,SAAS,OAAO,cAAc,OAAO,aAAa,OAAO,QAAQ,CAAC;AAGxE,UAAI,eAAe,WAAW,GAAG;AAC/B,eAAO;AAAA,UACL,MAAM;AAAA,UACN,YAAY;AAAA,UACZ,cAAc;AAAA,UACd,eAAe;AAAA,QACjB;AAAA,MACF;AAGA,UAAI,cAAc,eAAe,KAAK,OAAK,MAAM,QAAQ;AACzD,UAAI,CAAC,aAAa;AAEhB,sBAAc,eAAe,KAAK,OAAK,EAAE,SAAS,MAAM,QAAQ,KAAK,EAAE,SAAS,OAAO,QAAQ,CAAC;AAAA,MAClG;AACA,UAAI,CAAC,aAAa;AAEhB,cAAM,YAAY,SAAS,MAAM,GAAG,EAAE,IAAI,KAAK;AAC/C,sBAAc,eAAe,KAAK,OAAK;AACrC,gBAAM,SAAS,EAAE,MAAM,GAAG,EAAE,IAAI,KAAK;AACrC,iBAAO,WAAW;AAAA,QACpB,CAAC;AAAA,MACH;AACA,UAAI,CAAC,aAAa;AAEhB,sBAAc,eAAe,KAAK,OAAK,EAAE,SAAS,QAAQ,KAAK,SAAS,SAAS,EAAE,MAAM,GAAG,EAAE,IAAI,KAAK,EAAE,CAAC;AAAA,MAC5G;AAEA,UAAI,aAAa;AACf,eAAO;AAAA,UACL,MAAM;AAAA,UACN,YAAY;AAAA,QACd;AAAA,MACF,OAAO;AAEL,gBAAQ,IAAI,8DAA8D,QAAQ,EAAE;AACpF,gBAAQ,IAAI,qCAAqC,eAAe,KAAK,IAAI,CAAC,EAAE;AAC5E,eAAO;AAAA,UACL,MAAM;AAAA,UACN,YAAY;AAAA,UACZ,cAAc;AAAA,UACd,eAAe;AAAA,QACjB;AAAA,MACF;AAAA,IACF;AAGA,QAAI,OAAO,QAAQ,OAAO,OAAO,SAAS,UAAU;AAClD,YAAM,WAAW,OAAO;AACxB,YAAM,SAAS,OAAO,QAAQ,OAAO,aAAa,OAAO,cAAc,CAAC;AAExE,YAAM,cAAc,eAAe;AAAA,QAAK,OACtC,MAAM,YAAY,EAAE,SAAS,QAAQ;AAAA,MACvC;AAEA,UAAI,aAAa;AACf,eAAO;AAAA,UACL,MAAM;AAAA,UACN,YAAY;AAAA,QACd;AAAA,MACF,OAAO;AACL,eAAO;AAAA,UACL,MAAM;AAAA,UACN,YAAY;AAAA,UACZ,cAAc;AAAA,UACd,eAAe;AAAA,QACjB;AAAA,MACF;AAAA,IACF;AAAA,EACF,QAAQ;AAAA,EAER;AAEA,SAAO;AACT;AAGC,OAAe,KAAK;AACpB,OAAe,QAAQ;AAGxB,OAAO,cAAc,IAAI,YAAY,uBAAuB,CAAC;AAE7D,QAAQ,IAAI,6BAA6B;AAAA,EACvC,aAAa,OAAQ,OAAe,OAAO;AAAA,EAC3C,gBAAgB,OAAQ,OAAe,UAAU;AACnD,CAAC;",
  "names": ["content"]
}
